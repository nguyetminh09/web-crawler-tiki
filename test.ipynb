{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install underthesea # work_tokenize, sentiment\n",
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup # parse html\n",
    "import re #regex\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import joblib\n",
    "from underthesea import word_tokenize #word_tokenize of lines\n",
    "import numpy as np\n",
    "import transformers as ppb # load model BERT\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from sklearn.model_selection import train_test_split\n",
    "# scrap comment = selenium\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craw comment of product tiki, lazada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_url_selenium_lazada(url):\n",
    "    # Selenium\n",
    "    driver = webdriver.Chrome(\n",
    "        executable_path=\"C:/Users/DE/Desktop/Crawler/chromedriver.exe\")\n",
    "    print(\"Loading url=\", url)\n",
    "    driver.get(url)\n",
    "    list_review = []\n",
    "    # just craw 10 page\n",
    "    # x=0\n",
    "    # while x<10:\n",
    "    #     # try:\n",
    "    #     #     #Get the review details here\n",
    "    #     #     WebDriverWait(driver,5).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR,\".mod-reviews\")))\n",
    "    #     # except:\n",
    "    #     #     print('No comment')\n",
    "    #     #     break\n",
    "    #     # x +=1\n",
    "    #     product_reviews = driver.find_elements_by_css_selector(\"[class='item']\")\n",
    "    #     # Get product review\n",
    "    #     for product in product_reviews:\n",
    "    #         review = product.find_element_by_css_selector(\"[class='content']\").text\n",
    "    #         if (review != \"\" or review.strip()):\n",
    "    #             print(review, \"\\n\")\n",
    "    #             list_review.append(review)\n",
    "    #     #Check for button next-pagination-item have disable attribute then jump from loop else click on the next button\n",
    "    #     if len(driver.find_elements_by_css_selector(\"button.next-pagination-item.next[disabled]\"))>0:\n",
    "    #         break\n",
    "    #     else:\n",
    "    #         button_next=WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"button.next-pagination-item.next\")))\n",
    "    #         driver.execute_script(\"arguments[0].click();\", button_next)\n",
    "    #         print(\"next page\")\n",
    "    #         time.sleep(2)\n",
    "    #         x +=1\n",
    "    driver.close()\n",
    "    return list_review\n",
    "\n",
    "\n",
    "def load_url_selenium_tiki(url):\n",
    "    driver = webdriver.Chrome(\n",
    "        executable_path=\"C:/Users/DE/Desktop/Crawler/chromedriver.exe\")\n",
    "    print(\"Loading url=\", url)\n",
    "    driver.get(url)\n",
    "    list_review = []\n",
    "    # just craw 10 page\n",
    "    x = 0\n",
    "    while x < 10:\n",
    "        last = None\n",
    "        for v in range(500):\n",
    "            for k in range(5):\n",
    "                driver.find_element_by_xpath('//html').send_keys(Keys.DOWN)\n",
    "\n",
    "            if last is not None and last == driver.execute_script('return window.pageYOffset;'):\n",
    "                break\n",
    "            last = driver.execute_script('return window.pageYOffset;')\n",
    "\n",
    "        comment = driver.find_elements(By.XPATH, value=\"//div[@class='review-comment__content']\")\n",
    "\n",
    "        for review in comment:\n",
    "            review_comment = review.text\n",
    "            if (review_comment != \"\" or review_comment.strip()):\n",
    "                list_review.append(review_comment)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Check for button next-pagination-item have disable attribute then jump from loop else click on the next button\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[@class='btn next']\").click()\n",
    "            print(\"next page\")\n",
    "            time.sleep(2)\n",
    "            x += 1\n",
    "        except (TimeoutException, WebDriverException) as e:\n",
    "            print('Load several page!')\n",
    "            break\n",
    "    driver.close()\n",
    "    return list_review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard data, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize_data(row):\n",
    "    # remove stopword\n",
    "    # Remove . ? , at index final\n",
    "    row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
    "    # Remove all . , \" ... in sentences\n",
    "    row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
    "        .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
    "        .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
    "        .replace('\"', \" \").replace(\"'\", \" \") \\\n",
    "        .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
    "        .replace(\"-\", \" \").replace(\"?\", \" \")\n",
    "\n",
    "    row = row.strip()\n",
    "    return row\n",
    "\n",
    "# Tokenizer\n",
    "def tokenizer(row):\n",
    "    return word_tokenize(row, format=\"text\")\n",
    "\n",
    "def analyze(result):\n",
    "    bad = np.count_nonzero(result)\n",
    "    good = len(result) - bad\n",
    "    print(\"No of bad and neutral comments = \", bad)\n",
    "    print(\"No of good comments = \", good)\n",
    "\n",
    "    if good>bad:\n",
    "        return \"Good! You can buy it!\"\n",
    "    else:\n",
    "        return \"Bad! Please check it carefully!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data):\n",
    "    # 1. Standardize data\n",
    "    data_frame = pd.DataFrame(data)\n",
    "    print('data frame:', data_frame)\n",
    "    data_frame[0] = data_frame[0].apply(standardize_data)\n",
    "\n",
    "    # 2. Tokenizer\n",
    "    data_frame[0] = data_frame[0].apply(tokenizer)\n",
    "\n",
    "    # 3. Embedding\n",
    "    X_val = data_frame[0]\n",
    "    return X_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrain model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrainModel(data):\n",
    "    \n",
    "    '''\n",
    "    Load pretrain model/ tokenizers\n",
    "    Return : features\n",
    "    '''\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    #encode lines\n",
    "    tokenized = data.apply((lambda x: tokenizer.encode(x, add_special_tokens = True)))\n",
    "\n",
    "    # get lenght max of tokenized\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    print('max len:', max_len)\n",
    "\n",
    "    # if lenght of tokenized not equal max_len , so padding value 0\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    print('padded:', padded[1])\n",
    "    print('len padded:', padded.shape)\n",
    "\n",
    "    #get attention mask ( 0: not has word, 1: has word)\n",
    "    attention_mask = np.where(padded ==0, 0,1)\n",
    "    print('attention mask:', attention_mask[1])\n",
    "\n",
    "    # Convert input to tensor\n",
    "    padded = torch.tensor(padded)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "\n",
    "    # Load model\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(padded, attention_mask =attention_mask)\n",
    "    #     print('last hidden states:', last_hidden_states)\n",
    "\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    print('features:', features)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE\\AppData\\Local\\Temp\\ipykernel_7740\\1979255434.py:39: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading url= https://tiki.vn/combo-dau-goi--dau-xa-tresemme-keratin-smooth-duong-toc-kho-xo-roi-cong-thuc-chuan-salon-hydrolyzed-keratin-trong-dau-goi-va-dau-xa-duong-toc-vao-nep-suon-muot-640g--620g-p22254660.html?spid=22254661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE\\AppData\\Local\\Temp\\ipykernel_7740\\1979255434.py:50: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath('//html').send_keys(Keys.DOWN)\n",
      "C:\\Users\\DE\\AppData\\Local\\Temp\\ipykernel_7740\\1979255434.py:67: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath(\"//a[@class='btn next']\").click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "next page\n",
      "['Mở hộp ra thấy mùi thơm dễ chịu, đóng gói cẩn thận. Chưa dùng nên chưa bik chất lượng sản phẩm ntn. Có quà tặng đi kèm. Nói chung chim ưng okokokokokokokokeuwuwuwuwiieiwuwiwiwiwiwiwiwieieieieieiejejejeieieieoeoeoeoeoeeoeowooeoeeoeooeoeoeoeowowowowowoeoeoeoeoeoeoeoeoeoeoeoeoeoe', 'TIKI giao hàng maxxxxx nhanh luôn ạ. 10h tối đặt, 10h sáng đã gọi xuống nhận hàng. Đóng gói cẩn thận, ko dùng túi chống sốc nilon mà dùng thùng giấy tái sử dụng ???. Săn sale chính hãng giá rẻ, sản phẩm mùi thơm hơi nặng, tóc bóng mượt, ko bị khô.', 'Giao hàng siêu nhanh, tối hôm trước hôm sau đã có hàng. Sản phẩm được tặng kèm nhiều thứ . Dầu gội thơm, nhưng dùng dầu xả thì phải xả kĩ không tóc dễ bết dầu. Dùng 1 thời gian chưa thấy tóc chẻ ngọn. Mới dùng thì sau khi sấy xong tóc khá mượt. Được nửa chai bắt đầu thấy có vẻ hơi khô so với loại trước mình dùng.', 'MÓN QUÀ Ý NGHĨA CỦA KHÓA SINH CLB LA HẦU LA CÚNG DƯỜNG SƯ PHỤ NHÂN DỊP 20/11 --- Với tâm kính yêu Sư Phụ, vừa qua, các bạn khóa sinh CLB La Hầu La đã thực hành hạnh hiếu, gửi tặng một món quà ý nghĩa do tự tay các bạn làm để dâng lên cúng dường Sư Phụ nhân dịp Hiến chương Nhà giáo 20/11. Chuẩn bị cho món quà đặc biệt này, các bạn khóa sinh đã rất khéo léo, từ lên ý tưởng nội dung đến việc thực hiện cắt giấy, làm thiệp, vẽ tranh,... Món quà chính là tình cảm tri ân của các bạn khóa sinh dâng lên Sư Phụ. Ban Quản trị xin gửi tới quý Phật tử và các bạn một số hình ảnh các bạn khóa sinh CLB La Hầu... Xem thêm', 'dầu thơm lắm. chưa dùng nên chưa biết có thích k. shop đóng gói rất cẩn thận ạ.', 'Sản phẩm đúng như mô tả. Giao hàng nhanh hơn dự kiến. Chưa sử dụng chưa biết chất lượng', 'Mình chưa xài nên chưa thể đánh giá về chất lượng sản phẩm được, nhưng về mùi thì rất thơm, chưa mở nắp mà hương thơm đã lan tỏa khắp phòng rồi. Được tặng kèm máy sấy tóc nhỏ nhỏ xinh xinh của Sunhouse, máy kêu tiếng hơi to, gió tạm ổn thôi chứ không mạnh lắm, nhưng được cái nhỏ gọn, có thể mang theo khi đi du lịch.', 'Thấy quảng cáo dùng cho tóc nhuộm, chưa sử dụng. Dùng thử xem hợp sẽ ủng hộ shop nha. Gói ghém từng chai, hàng đẹp. Cám ơn Tiki và shop nha.', 'Đánh giá lại sản phẩm, lúc gội không thơm nhưng lưu hương dễ chịu trên tóc. Sử dụng sản phẩm này mình thấy tóc giảm gãy rụng hơn rất nhiều và tóc thì siêu mượt và mềm.', 'Tiki giao hàng nhanh , đóng hàng cẩn thận , sản phẩm chưa dùng nên ko biết , ảnh mang tính chất nhận xu vì đang đi làm ko chuppp đc', 'Mình mua combo này sale 20% còn được tặng máy sấy tóc bé bé mang đi du lịch cute lém. Mình vừa xài chai dầu xả thấy mượt và thơm lắm. Vận chuyển ok không bị hư hỏng gì hết. Khá đáng tiền cho 5? nhé hehe', 'tg giao hàng mùa dịch tương đối nhanh, hàng tiki trading lần đầu mua nhg ấn tượng khá tốt cả về hình thức gói hàng lẫn anh giao hàng. Còn về chất lượng dầu siêu thơm luôn. chim ưng nha', 'Mua về trước để sau này lên trọ xài nên chưa biết chất lượng sản phẩm ra sao Tuy nhiên đánh giá luôn 5 sao cho tiki vì vận chuyển thần tốc. Mình ở ngoại tỉnh mà đặt hôm trc hôm sau đã về hàng luôn. Siêu ưng tiki', 'Giao hàng nhanh(giao trước thời gian định kiến 1 ngày); shipper thân thiện; sản phẩm chưa dùng nên chưa biết chất lượng như nào nhưng nhìn chung, mẫu mã ok, được sale và tặng(khá thích). Mọi người nên mua nha. Lời cuối, chúc shop ngày càng phát triển và chất lượng sản phẩm ngày càng tốt hơn cho người tiêu dùng', 'Sản phẩm y hình. Đc tặng thêm máy sấy tóc siêu kute. Mình dùng dòng này thấy tóc mềm mượt hơn rất nhiều so với các sp khác nên mua dùng lại. Giao hàng nhanh và đóng gói hàng của tiki thì k có gì để bàn cãi. Sẽ luôn ủng hộ tiki', 'rất thơm và giữ nếp tóc rất tốt so với những loại dầu gội khác. k bị kiểu mấy sợi tóc lởm chởm. ship hang cũng rất la nhanh. giá lại rẻ nhưng mình k hạp lắm nên sd bị gàu và ngứa da đầu. vẫn đánh giá 5 sao vì thơm', 'Bộ đôi này dùng tốt cho tóc từ hơi khô hư tổn một chút đến khô và hư tổn nhiều đều hợp.', 'dịch nhưng giao nhanh, mở hộp ra thấy rất thơm. k biết gội thì tn. giao hàng nhanh. ưng cái bụng 😍😍😍😍😍😍😍😍😍😍😍😍😍😍😍', 'đóng gói tốt, gửi hàng nhanh chóng, sản phẩm có mùi thơm dễ chịu, nói chung là hài lòng (mỗi tội không thấy cái túi quà tặng đâu cả 😁)', 'mới mở ra mùi thơm cực xả khoảng 2tuần là tóc mềm mượt ra hẳn', 'Sp tôt, hết thì đặt lại thôi, may thay lúc đang KM', 'Mình nhuộm như này nên mua sản phẩm này. Chưa sử dụng nên ko biết nói sao. Cầm thấy chắc chắn, nặng tay. Cũng thơm nữa, nên yên tâm! Date khá xa nên ko có lo lắng gì, giao hàng nhanh và cẩn thận.', 'Mở hộp hàng ra mùi khá thơm. Giá cả rất ổn còn được freeship . Rất ok nhé . Mng nên mua sử dụng', 'Hàng rất ok phù hợp với giá tiền đóng gói cẩn thận giao hàng nhanh nhân viên giao hàng nhiệt tình chu đáo.Cảm ơn Tiki sẽ ủng hộ những lần mua tiếp theo.like like', 'dầu gội này phải gọi là cực thơm, vừa mở hộp ra đã thấy mùi rất dễ chịu, sản phẩm tặng kèm tuy nhỏ nhưng dùng cũng ổn. ship hàng rất nhanh. 5sao quá xứng đáng.', 'Dầu gội rất thơm . mượt tóc , lư hương rất lâu . Mùi hương cực kỳ dễ chịu 🥰', 'Chất lượng tốt, tóc bóng khoẻ, không bị gàu ngứa. Quà tặng nhiều', 'Đóng gói cẩn thận. Shipper nhiệt tình. Chưa dùng nên chưa đánh giá được hiệu quà. Nhưng vừa mở gói hàng ra đã thấy rất thơm. Chất lượng chắc 👍, vì đây là loại dầu gội đã có thương hiệu 😃', 'Đặt hàng hôm qua, hôm nay đã nhận được, nhưng sao mình mua ko được khuyến mại máy sấy tóc nhỉ?', 'giao đúng hàng, mới mua xài lần đầu tiên nên chưa biết thế nào. Đặt hôm 10/10 thấy trên web có kèm quà tặng, nhưng lúc nhận hàng lại ko có.', 'Dùng quen loại này rồi, tóc mềm mượt, có dưỡng tốt, Tiki giao hàng nhanh', 'Giao hàng rất nhanh , tuy là săn sale hơi mệt nhưng xứng đáng , còn được nhiều ưu đãi, đây là lần đầu mình mua đồ ở tiki, nhưng khá hài lòng ạ', 'Giao hàng nhanh chóng, dầu gội HSD còn mới, mua được giá quá ưu đãi còn được tặng thêm máy sấy rất đẹp. Hài lòng 👍', 'Giao hàng nhanh chóng,đóng gói chắc chắn,kèm theo quà tặng.Mình chưa sử dụng nên không biết chất lượng sản phẩm thế nào nói chung là đáng muaa🥳', 'gói hàng kĩ. đc tặng kèm kem ủ tóc rất ưng. mùi hương sản phẩm thơm. mua sale 242k bộ sp cảm thấy ưng ý.Hình ảnh k lq.sr mn', 'mua đợt sale giá rẻ mà còn đc tặng chai sữa rửa mặt.Tuy trên kiện hàng có dán chú ý hàng dễ vỡ nhưng lúc nhận hàng hộp vẫn móp méo và bị nứt ở đáy chai nên bị chảy ít dầu gội.', 'Giao hàng nhanh và đóng gói cẩn thận không bị hư hàng. Mặc dù mình mua không trong khung giờ quà tặng nhưng lúc nhận thì có luôn hũ ủ tóc tặng kèm. Quá tuyệt vời', 'ủa mk có thấy khuyến mại là máy sấy tóc mà lúc nhận hàng hổng có', 'sp đỉnh, dầu xả thơm cực kì, săn dc sale, tăng máy sấy dùng rất ổn áp', 'Rất hài lòng. Dầu gội ko những sạch mà còn rất thơm. Dầu xả cũng khỏi bàn. Nói chung là rất chym ưng. Cảm ơn shop. Cảm ơn tiki!', 'Mùi khá thơm, dầu gội ở mức ổn, tóc xơ quá k nên dùng, dầu xả dùng k bị bết tóc, dưỡng tốt.', 'mình đặt trong đợt dịch nhưng hàng vẫn giao tới rất ok, sp thì mình sài lâu rồi và thấy rất nhiều người chuộng dòng này', 'Đóng gói cẩn thận,giao hàng nhanh,sp chuẩn. Đc tặng kèm lọ ủ rất ưng ý.Sẽ ủng hộ shop lâu dài ạk❤️', 'E mua cặp này về nhưng 20/10 lại vừa đc tặng 1 cặp y hệt :( Pass cho ai cần giá 150k chưa unbox lun ạ Em ở Hà Nội', 'Thơm quá trời luôn nhưng chưa biết hiệu quả như thế nào. Cảm ơn tiki nhiều nhé. Giao hàng nhanh tuy ở TP HCM.', 'Hàng đóng gói rất kỹ. Nhưng hk thích vì giao hàng rất lâu. Làm phải đi mua chỗ khác giờ mới giao tới.', 'giao hàng nhanh , sản phẩm dùng rất thích', 'Hàng đóng gói cẩn thận, sản phẩm tốt', 'Chưa thấy giao sản phẩm tặng, dầu gội và dầu xả thơm, date 2024. Giao tiki now nên nhận hàng rất nhanh']\n",
      "data frame:                                                     0\n",
      "0   Mở hộp ra thấy mùi thơm dễ chịu, đóng gói cẩn ...\n",
      "1   TIKI giao hàng maxxxxx nhanh luôn ạ. 10h tối đ...\n",
      "2   Giao hàng siêu nhanh, tối hôm trước hôm sau đã...\n",
      "3   MÓN QUÀ Ý NGHĨA CỦA KHÓA SINH CLB LA HẦU LA CÚ...\n",
      "4   dầu thơm lắm. chưa dùng nên chưa biết có thích...\n",
      "5   Sản phẩm đúng như mô tả. Giao hàng nhanh hơn d...\n",
      "6   Mình chưa xài nên chưa thể đánh giá về chất lư...\n",
      "7   Thấy quảng cáo dùng cho tóc nhuộm, chưa sử dụn...\n",
      "8   Đánh giá lại sản phẩm, lúc gội không thơm nhưn...\n",
      "9   Tiki giao hàng nhanh , đóng hàng cẩn thận , sả...\n",
      "10  Mình mua combo này sale 20% còn được tặng máy ...\n",
      "11  tg giao hàng mùa dịch tương đối nhanh, hàng ti...\n",
      "12  Mua về trước để sau này lên trọ xài nên chưa b...\n",
      "13  Giao hàng nhanh(giao trước thời gian định kiến...\n",
      "14  Sản phẩm y hình. Đc tặng thêm máy sấy tóc siêu...\n",
      "15  rất thơm và giữ nếp tóc rất tốt so với những l...\n",
      "16  Bộ đôi này dùng tốt cho tóc từ hơi khô hư tổn ...\n",
      "17  dịch nhưng giao nhanh, mở hộp ra thấy rất thơm...\n",
      "18  đóng gói tốt, gửi hàng nhanh chóng, sản phẩm c...\n",
      "19  mới mở ra mùi thơm cực xả khoảng 2tuần là tóc ...\n",
      "20  Sp tôt, hết thì đặt lại thôi, may thay lúc đan...\n",
      "21  Mình nhuộm như này nên mua sản phẩm này. Chưa ...\n",
      "22  Mở hộp hàng ra mùi khá thơm. Giá cả rất ổn còn...\n",
      "23  Hàng rất ok phù hợp với giá tiền đóng gói cẩn ...\n",
      "24  dầu gội này phải gọi là cực thơm, vừa mở hộp r...\n",
      "25  Dầu gội rất thơm . mượt tóc , lư hương rất lâu...\n",
      "26  Chất lượng tốt, tóc bóng khoẻ, không bị gàu ng...\n",
      "27  Đóng gói cẩn thận. Shipper nhiệt tình. Chưa dù...\n",
      "28  Đặt hàng hôm qua, hôm nay đã nhận được, nhưng ...\n",
      "29  giao đúng hàng, mới mua xài lần đầu tiên nên c...\n",
      "30  Dùng quen loại này rồi, tóc mềm mượt, có dưỡng...\n",
      "31  Giao hàng rất nhanh , tuy là săn sale hơi mệt ...\n",
      "32  Giao hàng nhanh chóng, dầu gội HSD còn mới, mu...\n",
      "33  Giao hàng nhanh chóng,đóng gói chắc chắn,kèm t...\n",
      "34  gói hàng kĩ. đc tặng kèm kem ủ tóc rất ưng. mù...\n",
      "35  mua đợt sale giá rẻ mà còn đc tặng chai sữa rử...\n",
      "36  Giao hàng nhanh và đóng gói cẩn thận không bị ...\n",
      "37  ủa mk có thấy khuyến mại là máy sấy tóc mà lúc...\n",
      "38  sp đỉnh, dầu xả thơm cực kì, săn dc sale, tăng...\n",
      "39  Rất hài lòng. Dầu gội ko những sạch mà còn rất...\n",
      "40  Mùi khá thơm, dầu gội ở mức ổn, tóc xơ quá k n...\n",
      "41  mình đặt trong đợt dịch nhưng hàng vẫn giao tớ...\n",
      "42  Đóng gói cẩn thận,giao hàng nhanh,sp chuẩn. Đc...\n",
      "43  E mua cặp này về nhưng 20/10 lại vừa đc tặng 1...\n",
      "44  Thơm quá trời luôn nhưng chưa biết hiệu quả nh...\n",
      "45  Hàng đóng gói rất kỹ. Nhưng hk thích vì giao h...\n",
      "46          giao hàng nhanh , sản phẩm dùng rất thích\n",
      "47               Hàng đóng gói cẩn thận, sản phẩm tốt\n",
      "48  Chưa thấy giao sản phẩm tặng, dầu gội và dầu x...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len: 277\n",
      "padded: [  101 14841  3211 27699  2080  6865  4098 20348 20348 18699  2319  2232\n",
      " 11320  2239  1037  2184  1044  2000  2072  1102  4017  2184  1044  6369\n",
      "  1102  2050  2175  2072 15990  5063 18699  2319  6865  1102  5063  1035\n",
      "  2175  2072  2064  1035  2084 12849 29328 10722  2072 24008 27084  9152\n",
      "  7811  5003 29328 16215  5575 27699  2100 13843 10514  1035 29328  2624\n",
      "  5096  5413  2232  6865 27699  2128  2624  1035  6887  3286 14163  2072\n",
      " 19438  7570  2072 16660  2290  2000  2278 14753  2290 14163  4140 12849\n",
      " 12170  1047  6806   102     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0]\n",
      "len padded: (49, 277)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "features: [[-0.79686916  0.25831616 -0.17092465 ... -0.06376038  0.41097632\n",
      "   0.5428331 ]\n",
      " [-0.71481806  0.00668967  0.525615   ...  0.27145153  0.25163913\n",
      "   0.60267395]\n",
      " [-0.62145656  0.49094996  0.37198925 ...  0.1791565   0.4949839\n",
      "   0.39034176]\n",
      " ...\n",
      " [-0.7060085   0.1352287   0.03730997 ...  0.18559776  0.42867145\n",
      "   0.5181917 ]\n",
      " [-0.7691586   0.24052596  0.04822956 ...  0.17530443  0.49058998\n",
      "   0.3253925 ]\n",
      " [-0.68744653 -0.0618634   0.3132209  ... -0.0528369   0.55484796\n",
      "   0.3409016 ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1.]\n",
      "No of bad and neutral comments =  2\n",
      "No of good comments =  47\n",
      "Good! You can buy it!\n"
     ]
    }
   ],
   "source": [
    "def predict(url):\n",
    "    # 1. Load URL and print comments\n",
    "    if url== \"\":\n",
    "        url = \"https://tiki.vn/dien-thoai-samsung-galaxy-m31-128gb-6gb-hang-chinh-hang-p58259141.html\"\n",
    "    # data = load_url_selenium_lazada(url)\n",
    "    data = load_url_selenium_tiki(url)\n",
    "    print(data)\n",
    "    a_file = open(\"data_crawler.csv\", \"w\",  encoding='utf-8')\n",
    "    for row in data:\n",
    "        a_file.write(row + \"\\n\")\n",
    "\n",
    "    a_file.close()\n",
    "    data = processing_data(data)\n",
    "    features = load_pretrainModel(data)\n",
    "    # 2. Load weights\n",
    "    model = joblib.load('save_model.pkl')\n",
    "    # 3. Result\n",
    "    result = model.predict(features)\n",
    "    print(result)\n",
    "    print(analyze(result))\n",
    "\n",
    "predict(url ='https://tiki.vn/combo-dau-goi--dau-xa-tresemme-keratin-smooth-duong-toc-kho-xo-roi-cong-thuc-chuan-salon-hydrolyzed-keratin-trong-dau-goi-va-dau-xa-duong-toc-vao-nep-suon-muot-640g--620g-p22254660.html?spid=22254661')\n",
    "# predict(url = 'https://www.lazada.vn/products/op-lung-iphone-6-6s-plus-7-plus-8-plus-x-xr-xsmax-11-11-pro-11-promax-12-12-pro-12-promax-13-promax-trong-suot-chong-soc-i1277055288-s7560624279.html?search=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45c4f8f21a0eb8a118c781bdd48c3d315da4aac6ad95b6ecc57508b25afb6aa1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
